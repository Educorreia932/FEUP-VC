{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchinfo import summary\n",
    "import torchmetrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImage(image, title=\"\"):\n",
    "    if (len(image.shape) == 3):\n",
    "        cmap = None\n",
    "    else:\n",
    "        cmap = \"gray\"\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613 264\n"
     ]
    }
   ],
   "source": [
    "# get train and validation datasets\n",
    "images_directory = \"../dataset/images\"\n",
    "annotations_directory = \"../dataset/annotations\"\n",
    "\n",
    "with open(\"train.txt\") as train:\n",
    "    train_images_filenames = sorted(train.read().splitlines())\n",
    "\n",
    "with open(\"test.txt\") as test:\n",
    "    val_images_filenames = sorted(test.read().splitlines())\n",
    "\n",
    "# filter out images that can not be loaded properly\n",
    "train_images_filenames = [i for i in train_images_filenames if cv.imread(\n",
    "    os.path.join(images_directory, i + \".png\")) is not None]\n",
    "val_images_filenames = [i for i in val_images_filenames if cv.imread(\n",
    "    os.path.join(images_directory, i + \".png\")) is not None]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train_images_filenames)\n",
    "random.shuffle(val_images_filenames)\n",
    "\n",
    "print(len(train_images_filenames), len(val_images_filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, images_filenames, images_directory, transform=None):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.images_directory = images_directory\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "        image = cv.imread(os.path.join(\n",
    "            self.images_directory, image_filename + \".png\"))\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        # transform image into 0-1 range\n",
    "        # note that the ToTensorV2 method from the albumentations library does not automatically convert the image range into 0-1\n",
    "        image = image / 255.\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\notebook.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/notebook.ipynb#ch0000005?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m TrafficSignDataset(train_images_filenames, images_directory)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/notebook.ipynb#ch0000005?line=3'>4</a>\u001b[0m displayImage(train_dataset[\u001b[39m10\u001b[39;49m])\n",
      "\u001b[1;32mc:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\notebook.ipynb Cell 5'\u001b[0m in \u001b[0;36mTrafficSignDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/notebook.ipynb#ch0000003?line=20'>21</a>\u001b[0m     transformed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image\u001b[39m=\u001b[39mimage)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/notebook.ipynb#ch0000003?line=21'>22</a>\u001b[0m     image \u001b[39m=\u001b[39m transformed[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/notebook.ipynb#ch0000003?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m image\u001b[39m.\u001b[39;49mfloat64()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float64'"
     ]
    }
   ],
   "source": [
    "train_dataset = TrafficSignDataset(train_images_filenames, images_directory)\n",
    "\n",
    "\n",
    "displayImage(train_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
