{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\program files\\python310\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.22.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\program files\\python310\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (4.5.5.64)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8)) (9.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (0.12.0+cu113)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14)) (4.64.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.20.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 22)) (1.4.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 23)) (0.11.2)\n",
      "Requirement already satisfied: ipython in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (8.1.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 36)) (5.9.0)\n",
      "Requirement already satisfied: thop in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 37)) (0.0.31.post2005241907)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.2.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (1.26.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.7.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.41.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (2.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (1.46.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\program files\\python310\\lib\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (58.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 22)) (2022.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (3.0.28)\n",
      "Requirement already satisfied: backcall in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from stack-data->ipython->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 35)) (2.0.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ricardo\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import xml.etree.ElementTree as ET\n",
    "from utils import ModelTrainer, displayImage, importImage, plotTrainingHistory\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 123 264\n"
     ]
    }
   ],
   "source": [
    "# Get train and validation datasets\n",
    "images_directory = \"../dataset/images\"\n",
    "annotations_directory = \"../dataset/annotations\"\n",
    "\n",
    "train_split = 0.8\n",
    "\n",
    "with open(\"train.txt\") as train:\n",
    "    train_images_filenames_total = train.read().splitlines()\n",
    "\n",
    "    split_idx = int(train_split * len(train_images_filenames_total))\n",
    "    train_images_filenames = train_images_filenames_total[:split_idx]\n",
    "    val_images_filenames = train_images_filenames_total[split_idx:]\n",
    "\n",
    "\n",
    "with open(\"test.txt\") as test:\n",
    "    test_images_filenames = test.read().splitlines()\n",
    "\n",
    "# Filter out images that can not be loaded properly\n",
    "train_images_filenames = [i for i in train_images_filenames if cv.imread(os.path.join(images_directory, i + \".png\")) is not None]\n",
    "val_images_filenames = [i for i in val_images_filenames if cv.imread(os.path.join(images_directory, i + \".png\")) is not None]\n",
    "test_images_filenames = [i for i in test_images_filenames if cv.imread(os.path.join(images_directory, i + \".png\")) is not None]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train_images_filenames)\n",
    "random.shuffle(val_images_filenames)\n",
    "random.shuffle(test_images_filenames)\n",
    "\n",
    "print(len(train_images_filenames), len(val_images_filenames), len(test_images_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to YOLO annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "classes = {\n",
    "    \"trafficlight\": 0,\n",
    "    \"stop\": 1,\n",
    "    \"speedlimit\": 2,\n",
    "    \"crosswalk\": 3,\n",
    "}\n",
    "\n",
    "os.makedirs(\"../dataset/labels\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"dataset/images/train\", exist_ok=True)\n",
    "os.makedirs(\"dataset/images/val\", exist_ok=True)\n",
    "os.makedirs(\"dataset/images/test\", exist_ok=True)\n",
    "os.makedirs(\"dataset/labels/train\", exist_ok=True)\n",
    "os.makedirs(\"dataset/labels/val\", exist_ok=True)\n",
    "os.makedirs(\"dataset/labels/test\", exist_ok=True)\n",
    "\n",
    "\n",
    "for img in train_images_filenames:\n",
    "    shutil.copy(\n",
    "        f\"../dataset/images/{img}.png\", f\"dataset/images/train/{img}.png\")\n",
    "\n",
    "for img in val_images_filenames:\n",
    "    shutil.copy(\n",
    "        f\"../dataset/images/{img}.png\", f\"dataset/images/val/{img}.png\")\n",
    "\n",
    "for img in test_images_filenames:\n",
    "    shutil.copy(\n",
    "        f\"../dataset/images/{img}.png\", f\"dataset/images/test/{img}.png\")\n",
    "\n",
    "\n",
    "for path in os.listdir(annotations_directory):\n",
    "    with open(os.path.join(annotations_directory, path), \"r\") as xml:\n",
    "        folder = \"\"\n",
    "        if path.strip(\".xml\") in train_images_filenames:\n",
    "            folder = \"train\"\n",
    "        elif path.strip(\".xml\") in val_images_filenames:\n",
    "            folder = \"val\"\n",
    "        else:\n",
    "            folder = \"test\"\n",
    "\n",
    "\n",
    "        with open(f\"dataset/labels/{folder}/{path.replace('xml', 'txt')}\", \"w\") as txt:\n",
    "            tree = ET.parse(xml)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            size = root.find(\"size\")\n",
    "            height = int(size.find(\"height\").text)\n",
    "            width = int(size.find(\"width\").text)\n",
    "\n",
    "            objects = root.findall(\"object\")\n",
    "\n",
    "            lines = []\n",
    "            for object in objects:\n",
    "                class_index = classes[object.find(\"name\").text]\n",
    "\n",
    "                xmin = int(object.find(\"bndbox/xmin\").text)\n",
    "                ymin = int(object.find(\"bndbox/ymin\").text)\n",
    "                xmax = int(object.find(\"bndbox/xmax\").text)\n",
    "                ymax = int(object.find(\"bndbox/ymax\").text)\n",
    "\n",
    "                # middle of bbox\n",
    "                bbox_x = ((xmax + xmin) / 2) / width\n",
    "                bbox_y = ((ymax + ymin) / 2) / height\n",
    "                bbox_width = (xmax - xmin) / width\n",
    "                bbox_height = (ymax - ymin) / height\n",
    "\n",
    "                lines.append(\n",
    "                    f\"{class_index} {bbox_x} {bbox_y} {bbox_width} {bbox_height}\")\n",
    "\n",
    "            txt.write(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"trafficlight\": 0,\n",
    "    \"stop\": 1,\n",
    "    \"speedlimit\": 2,\n",
    "    \"crosswalk\": 3,\n",
    "}\n",
    "\n",
    "\n",
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, annotations_directory, images_filenames, images_directory, transform=None):\n",
    "        self.annotations_directory = annotations_directory\n",
    "        self.images_filenames = images_filenames\n",
    "        self.images_directory = images_directory\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "        image = cv.imread(os.path.join(\n",
    "            self.images_directory, image_filename + \".png\"))\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image = image / 255.\n",
    "\n",
    "        boxes, labels = self._get_boxes_and_labels(image_filename)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(\n",
    "                image=image, bboxes=target[\"boxes\"], labels=target[\"labels\"])\n",
    "            image = transformed[\"image\"]\n",
    "            target[\"boxes\"] = transformed[\"bboxes\"]\n",
    "            target[\"labels\"] = transformed[\"labels\"]\n",
    "            target[\"boxes\"] = torch.as_tensor(target[\"boxes\"], dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(target[\"labels\"], dtype=torch.int64)\n",
    "\n",
    "        return image.float(), target\n",
    "\n",
    "    # https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "    def _get_boxes_and_labels(self, filename):\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(os.path.join(self.annotations_directory, filename + \".xml\")) as xml:\n",
    "            tree = ET.parse(xml)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            objects = root.findall(\"object\")\n",
    "            for object in objects:\n",
    "                class_index = classes[object.find(\"name\").text]\n",
    "\n",
    "                xmin = int(object.find(\"bndbox/xmin\").text)\n",
    "                ymin = int(object.find(\"bndbox/ymin\").text)\n",
    "                xmax = int(object.find(\"bndbox/xmax\").text)\n",
    "                ymax = int(object.find(\"bndbox/ymax\").text)\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(class_index)\n",
    "\n",
    "        return boxes, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "# Get CPU or GPU device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 0  # how many processes are used to load the data\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(256, 256),\n",
    "        A.RandomCrop(224, 224),\n",
    "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2,\n",
    "                           rotate_limit=30, p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=['labels'])\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [A.Resize(256, 256), A.CenterCrop(224, 224), ToTensorV2()],\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=['labels'])\n",
    ")\n",
    "\n",
    "train = TrafficSignDataset(annotations_directory,\n",
    "                           train_images_filenames, images_directory, train_transform)\n",
    "val = TrafficSignDataset(annotations_directory,\n",
    "                         val_images_filenames, images_directory, val_transform)\n",
    "test = TrafficSignDataset(annotations_directory,\n",
    "                          test_images_filenames, images_directory)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True, collate_fn=lambda batch: tuple(zip(*batch)))\n",
    "val_dataloader = DataLoader(val, batch_size=batch_size,\n",
    "                            shuffle=False, num_workers=num_workers, drop_last=False, collate_fn=lambda batch: tuple(zip(*batch)))\n",
    "test_dataloader = DataLoader(\n",
    "    test, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "metric = JaccardIndex(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, epoch, optimizer=None, is_train=True):\n",
    "    if is_train:\n",
    "        assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, len(dataloader) - 1)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "        )\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for images, targets in tqdm(dataloader):\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            # loss_value = losses_reduced.item()\n",
    "            # losses_reduced = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if lr_scheduler is not None:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "            # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
    "            total_loss += losses.item()\n",
    "            # total_jaccard += metric(final_pred.cpu(), target.cpu())\n",
    "\n",
    "        return total_loss / num_batches # , total_jaccard / num_batches\n",
    "\n",
    "\n",
    "def evaluate(dataloader, model, metric):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for images, targets in tqdm(dataloader):\n",
    "            images = list(image.to(device) for image in images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            outputs = [{k: v.to(\"cpu\") for k, v in t.items()} for t in outputs]\n",
    "\n",
    "            print(outputs)\n",
    "            res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "            # print(res)\n",
    "\n",
    "            metric.update(outputs, targets)\n",
    "        \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:44<01:06,  7.38s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target boxes to be a tensor of shape [N, 4], got torch.Size([0]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\object_detection.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=36'>37</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=37'>38</a>\u001b[0m   train_loss \u001b[39m=\u001b[39m train_one_epoch(train_dataloader, model, t, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=38'>39</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=39'>40</a>\u001b[0m   \u001b[39m# val_loss = train_one_epoch(val_dataloader, model, t, optimizer, is_train=False)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=40'>41</a>\u001b[0m   \u001b[39m# meanap = evaluate(val_dataloader, model, metric)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000012?line=41'>42</a>\u001b[0m   \u001b[39m# print(f\"Val loss: {val_loss:.3f}\")\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\object_detection.ipynb Cell 12'\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(dataloader, model, epoch, optimizer, is_train)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=26'>27</a>\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(image\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=27'>28</a>\u001b[0m targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=29'>30</a>\u001b[0m loss_dict \u001b[39m=\u001b[39m model(images, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=30'>31</a>\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss \u001b[39mfor\u001b[39;00m loss \u001b[39min\u001b[39;00m loss_dict\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=31'>32</a>\u001b[0m \u001b[39m# loss_value = losses_reduced.item()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ricardo/Desktop/VC2022/Part2/object_detection.ipynb#ch0000011?line=32'>33</a>\u001b[0m \u001b[39m# losses_reduced = sum(loss for loss in loss_dict.values())\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:68\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torchvision/models/detection/generalized_rcnn.py?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(boxes, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torchvision/models/detection/generalized_rcnn.py?line=66'>67</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(boxes\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m boxes\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torchvision/models/detection/generalized_rcnn.py?line=67'>68</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected target boxes to be a tensor of shape [N, 4], got \u001b[39m\u001b[39m{\u001b[39;00mboxes\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torchvision/models/detection/generalized_rcnn.py?line=68'>69</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Ricardo/AppData/Roaming/Python/Python310/site-packages/torchvision/models/detection/generalized_rcnn.py?line=69'>70</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected target boxes to be of type Tensor, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(boxes)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected target boxes to be a tensor of shape [N, 4], got torch.Size([0])."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                step_size=3,\n",
    "                                                gamma=0.1)\n",
    "\n",
    "metric = MeanAveragePrecision()\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "train_history = {'loss': []}\n",
    "val_history = {'meanap': []}\n",
    "best_val_loss = np.inf\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     # train for one epoch, printing every 10 iterations\n",
    "#     train_one_epoch()\n",
    "#     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "#     # evaluate on the test dataset\n",
    "#     evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Start training...\")\n",
    "for t in range(num_epochs):\n",
    "  print(f\"\\nEpoch {t+1}\")\n",
    "  train_loss = train_one_epoch(train_dataloader, model, t, optimizer)\n",
    "  print(f\"Train loss: {train_loss:.3f}\")\n",
    "  # val_loss = train_one_epoch(val_dataloader, model, t, optimizer, is_train=False)\n",
    "  # meanap = evaluate(val_dataloader, model, metric)\n",
    "  # print(f\"Val loss: {val_loss:.3f}\")\n",
    "  print(meanap)\n",
    "\n",
    "  # save model when val loss improves\n",
    "  # if val_loss < best_val_loss:\n",
    "  #   best_val_loss = val_loss\n",
    "  #   save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "  #   torch.save(save_dict, 'best_model.pth')\n",
    "\n",
    "  # # save latest model\n",
    "  # save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "  # torch.save(save_dict, 'latest_model.pth')\n",
    "\n",
    "  # save training history for plotting purposes\n",
    "  train_history[\"loss\"].append(train_loss)\n",
    "  # train_history[\"jaccard\"].append(train_jaccard)\n",
    "\n",
    "  val_history[\"meanap\"].append(meanap)\n",
    "  # val_history[\"jaccard\"].append(val_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3741266108.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [17]\u001b[1;36m\u001b[0m\n\u001b[1;33m    python yolov5/train.py --batch -1 --epochs 3 --data trafficsigns.yaml --workers 0\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Might need to be run on linux/WSL\n",
    "!python3 yolov5/train.py --batch 10 --epochs 30 --data trafficsigns.yaml\n",
    "# python yolov5/train.py --batch -1 --epochs 3 --data trafficsigns.yaml --workers 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection\n",
    "!python3 yolov5/detect.py --weights yolov5/runs/train/exp22/weights/best.pt --img 640 --conf 0.25 --source dataset/images/train/road2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_train64_8.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)    \n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "_fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    import torch    import torch\n",
      "\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_train64_8.dll\" or one of its dependencies.\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cusolver64_11.dll\" or one of its dependencies.\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_train64_8.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cusparse64_11.dll\" or one of its dependencies.\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "      File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_infer64_8.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "      File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\curand64_10.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\torch_python.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 1 missing, 0 empty, 0 corrupt:   0%|          | 1/613 [00:06<1:08:53,  6.75s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 18 missing, 0 empty, 0 corrupt:   3%|▎         | 18/613 [00:06<02:42,  3.66it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "        return _run_module_code(code, init_globals, run_name,return _run_module_code(code, init_globals, run_name,\n",
      "\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "    import torch  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "    OSErrorraise err\n",
      ": [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_adv_train64_8.dll\" or one of its dependencies.\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 56 missing, 0 empty, 0 corrupt:   9%|▉         | 56/613 [00:06<00:38, 14.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 98 missing, 0 empty, 0 corrupt:  16%|█▌        | 98/613 [00:07<00:16, 30.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 141 missing, 0 empty, 0 corrupt:  23%|██▎       | 141/613 [00:07<00:09, 51.60it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 178 missing, 0 empty, 0 corrupt:  29%|██▉       | 178/613 [00:07<00:05, 73.85it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_infer64_8.dll\" or one of its dependencies.\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_infer64_8.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_cnn_train64_8.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 218 missing, 0 empty, 0 corrupt:  36%|███▌      | 218/613 [00:07<00:03, 103.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 260 missing, 0 empty, 0 corrupt:  42%|████▏     | 260/613 [00:07<00:02, 139.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 300 missing, 0 empty, 0 corrupt:  49%|████▉     | 300/613 [00:07<00:01, 176.15it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_adv_infer64_8.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 342 missing, 0 empty, 0 corrupt:  56%|█████▌    | 342/613 [00:07<00:01, 217.01it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError    raise err: \n",
      "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\curand64_10.dll\" or one of its dependencies.\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cusolver64_11.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 382 missing, 0 empty, 0 corrupt:  62%|██████▏   | 382/613 [00:07<00:00, 239.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 423 missing, 0 empty, 0 corrupt:  69%|██████▉   | 423/613 [00:07<00:00, 274.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 462 missing, 0 empty, 0 corrupt:  75%|███████▌  | 462/613 [00:08<00:00, 297.94it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cufft64_10.dll\" or one of its dependencies.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "      File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "exitcode = _main(fd, parent_sentinel)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "    prepare(preparation_data)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"c:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    main_content = runpy.run_path(main_path,\n",
      "      File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 269, in run_path\n",
      "exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 96, in _run_module_code\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_adv_train64_8.dll\" or one of its dependencies.\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 26, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\__init__.py\", line 126, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\Ricardo\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\lib\\cudnn_adv_train64_8.dll\" or one of its dependencies.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 520 missing, 0 empty, 0 corrupt:  85%|████████▍ | 520/613 [00:08<00:00, 364.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 600 missing, 0 empty, 0 corrupt:  98%|█████████▊| 600/613 [00:08<00:00, 476.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train' images and labels...0 found, 613 missing, 0 empty, 0 corrupt: 100%|██████████| 613/613 [00:08<00:00, 74.48it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train.cache\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 670, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 565, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\train.py\", line 221, in train\n",
      "    train_loader, dataset = create_dataloader(train_path,\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\utils\\dataloaders.py\", line 114, in create_dataloader\n",
      "    dataset = LoadImagesAndLabels(\n",
      "  File \"c:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\yolov5\\utils\\dataloaders.py\", line 461, in __init__\n",
      "    assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'\n",
      "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in C:\\Users\\Ricardo\\Desktop\\VC2022\\Part2\\dataset\\labels\\train.cache. Can not train without labels. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n"
     ]
    }
   ],
   "source": [
    "# yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', channels=3, classes=4, autoshape=False)\n",
    "# yolo_model.to(device)\n",
    "\n",
    "# yolo = {\n",
    "#     \"model\": yolo_model,\n",
    "#     \"name\": 'yolov5s',\n",
    "#     \"num_epochs\": 10,\n",
    "#     \"loss\": nn.CrossEntropyLoss(),  # already includes the Softmax activation\n",
    "#     \"optimizer\": torch.optim.SGD(yolo_model.parameters(), lr=1e-3)\n",
    "# }\n",
    "\n",
    "# print(yolo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
